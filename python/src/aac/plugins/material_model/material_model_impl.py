"""AaC Plugin implementation module for the material_model plugin."""
# NOTE: It is safe to edit this file.
# This file is only initially generated by the aac gen-plugin, and it won't be overwritten if the file already exists.

import os

from aac.lang.definition_helpers import get_models_by_type, convert_parsed_definitions_to_dict_definition
from aac.plugins.plugin_execution import (
    PluginExecutionResult,
    PluginExecutionStatusCode,
    plugin_result,
)
from aac.validate import validated_source

plugin_name = "material_model"


def gen_bom(architecture_file: str, output_directory: str) -> PluginExecutionResult:
    """
    Generate a Bill of Material from Arch-as-Code material models.

    Args:
        architecture_file (str): The yaml file containing the material models to generate the BOM.
        output_directory (str): The directory to write the generated BOM to.
    """
    def _prepend_value(bom_item: dict, field: str, value: str) -> None:
        # I'm assuming this will just change the dict passed in (as a side effect)
        bom_item_field = bom_item[field]
        if len(bom_item_field) > 0:
            bom_item[field] = f"{value} | {bom_item_field}"
        else:
            bom_item[field] = value

    def _process_deployment(deployment: dict, models: dict) -> list(dict()):
        bom_items = []
        deployment_name = deployment.get("name")
        # for each sub-deployment, process recursively
        for sub_deployment in deployment_dict.get("sub-deployments"):
            bom_items.append(_process_deployment(models.get(sub_deployment["name"]), models))

        # process each assembly_ref
        for assembly_ref in deployment_dict.get("assemblies"):
            assembly_items = _process_assembly(
                models.get(assembly_ref["name"]), assembly_ref["quantity"], assembly_ref["need_date"], models)

            # set need_date if included in the assembly_ref
            if "need_date" in assembly_ref.keys():
                for item in assembly_items:
                    item["need_date"] = assembly_ref["need_date"]

            # add assembly_items to the bom_items
            bom_items.append(assembly_items)

        # for each part in a deployment, generate a bom_item dict entry (be careful about quantities)
        for part_ref in deployment_dict.get("parts"):
            part_items = _process_part(models.get(part_ref["name"]), part_ref["quantity"])

            # set need_date if included in the part_ref
            if "need_date" in part_ref.keys():
                for item in part_items:
                    item["need_date"] = part_ref["need_date"]

            # add parts to bom_items
            bom_items.append(part_items)

        # prepend deployment name to all context fields in bom_items
        for item in bom_items:
            _prepend_value(item, "context", deployment["name"])

        return bom_items

    def _process_assembly(assembly: dict, assembly_qty: int, models: dict) -> list(dict()):
        bom_items = []
        # for each sub_assembly, process recursively
        for sub_assembly_ref in assembly.get("assemblies"):
            sub_assembly_items = _process_assembly(
                models.get(sub_assembly_ref["name"]), assembly_qty * int(sub_assembly_ref["quantity"]), models)

            # set need_date if included in the assembly_ref
            if "need_date" in sub_assembly_ref.keys():
                for item in sub_assembly_items:
                    item["need_date"] = sub_assembly_ref["need_date"]

            # add assembly_items to the bom_items
            bom_items.append(sub_assembly_items)

        # for each part, generate a bom_item dict entry (be careful about quantities)
        for part_ref in assembly.get("parts"):
            part_items = _process_part(models.get(part_ref["name"]), assembly_qty * int(part_ref["quantity"]))

            # set need_date if included in the part_ref
            if "need_date" in part_ref.keys():
                for item in part_items:
                    item["need_date"] = part_ref["need_date"]

            # add parts to bom_items
            bom_items.append(part_items)

        # prepend assembly name to all context fields in bom_items
        for item in bom_items:
            _prepend_value(item, "context", assembly["name"])

        return bom_items

    def _process_part(part: dict, part_qty: int, models:dict) -> list(dict()):
        return [{"make": part["make"], "model": part["model"], "description": part["description"],
            "unit_cost": part["unit_cost"], "quantity": part_qty, "total_cost": number(part["unit_cost"]) * part_qty}]

    def to_bom_csv(architecture_file: str, output_directory: str) -> str:
        architecture_file_path = os.path.abspath(architecture_file)
        file_name, _ = os.path.splitext(os.path.basename(architecture_file_path))

        with validated_source(architecture_file_path) as result:
            definitions_as_dict = convert_parsed_definitions_to_dict_definition(result.definitions)
            # TODO use the dict to generate BOM line items

            # TODO need to add in the design context by looking at the deployment/assembly structure and adding fields
            #      note:  this does not have to be of consistent depth for everything, so may need blanks in some cases
            #      note:  for now, let's just aggregate it into a single context field for simplicity
            bom_header = ["make", "model", "description", "unit_cost", "quantity", "total_cost", "location", "need_date", "context"]
            bom_items = []

            # get a list of the deployments
            deployment_types = get_models_by_type(models, "deployment")

            # remove any deployment listed as a sub-deployment in another deployment to get the root deployment(s)
            deployment_names = list(deployment_types.keys())
            for root_deployment_name in deployment_types.keys():
                deployment_dict = deployment_types.get(root_deployment_name)
                for sub_deployment in deployment_dict.get("sub-deployments"):
                    deployment_names.remove(sub_deployment.get("name"))

            # loop through the root deployment list, keeping track of context by appending deployment names
            print(deployment_names)
            for deployment_name in deployment_names:
                bom_items.append(_process_deployment(deployment_types.get(deployment_name), models, ""))

            if output_directory:
                if not os.path.exists(output_directory):
                    os.makedirs(output_directory)

                output_file_path = os.path.join(output_directory, f"{file_name}.csv")
                with open(output_file_path, "w") as out_file:
                    out_file.write(bom_csv)
                    return f"Wrote BOM to {output_file_path}."

            return f"File: {architecture_file_path}\n{bom_csv}\n"

    status = PluginExecutionStatusCode.SUCCESS
    messages = []
    for arch_file in architecture_files:
        with plugin_result(plugin_name, to_bom_csv, arch_file, output_directory) as result:
            messages += result.messages
            if not result.is_success():
                status = result.status_code

    return PluginExecutionResult(plugin_name, status, messages)
